{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5777370-e971-4fff-a676-44489a722d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL ANALYSIS TRAVEL SCHEDULE\n",
    "# CONVERT FINAL_ANALYSIS_YYYY_YY FILES TO JUST LOAD AND SAVE DATA TO CSV\n",
    "# THEN RUN ACTUAL ANALYSIS HERE\n",
    "\n",
    "#nba_team_lat_lon = get_team_lat_lon(nba_team_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedaec48-a7f6-44ab-8eff-c41aa30d0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nba_api\n",
    "from nba_api.stats.endpoints import leaguegamefinder, teamdetails, boxscoreadvancedv2, cumestatsteam\n",
    "from nba_api.stats.static import teams\n",
    "\n",
    "from geopy import geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef095c9a-6091-421a-b048-adb3eb59e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_ids():\n",
    "    nba_teams = teams.get_teams()\n",
    "    nba_team_ids = []\n",
    "    for team in nba_teams:\n",
    "        nba_team_ids.append(team['id'])\n",
    "        \n",
    "    return nba_team_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a73afe-582d-427b-840d-1fd028b48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_details():\n",
    "    nba_team_ids = get_team_ids()\n",
    "    \n",
    "    gn = Nominatim(user_agent='cs-5483-995-nba-travel')\n",
    "\n",
    "    nba_team_details = {}\n",
    "\n",
    "    for nba_team_id in nba_team_ids:\n",
    "        result = teamdetails.TeamDetails(team_id = nba_team_id)\n",
    "        team_details = result.get_data_frames()[0][['TEAM_ID','ABBREVIATION','NICKNAME','CITY']]\n",
    "    \n",
    "        team_details['FULL_NAME'] = team_details['CITY'] + \" \" + team_details['NICKNAME']\n",
    "\n",
    "        city_lat_long = gn.geocode(team_details['CITY'][0])\n",
    "    \n",
    "        team_details['LAT'] = city_lat_long.raw['lat']\n",
    "        team_details['LON'] = city_lat_long.raw['lon']\n",
    "    \n",
    "        team_details_dict = {'ID':nba_team_id, 'NICKNAME':team_details['NICKNAME'][0], 'CITY':team_details['CITY'][0], \n",
    "                         'FULL_NAME':team_details['FULL_NAME'][0], 'LAT':team_details['LAT'][0], 'LON':team_details['LON'][0]}\n",
    "    \n",
    "        nba_team_details[team_details['ABBREVIATION'][0]] = team_details_dict\n",
    "        \n",
    "    return nba_team_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a15bcbf-0d30-4f3c-bb73-a9e703c5a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nba_game_data(file_path='pd_data_files', base_filename='games_2016_17'):\n",
    "    games = pd.read_csv(file_path+'/'+base_filename+'.csv')\n",
    "    #games_adv = pd.read_csv(file_path+'/'+base_filename+'_adv.csv')\n",
    "    \n",
    "    #return games, games_adv\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87ba08b-442d-4b66-a25d-8080fe67e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_for_team(team_abbreviation, games):\n",
    "    \n",
    "    edge_pairs = []\n",
    "    unique_edge_pairs = []\n",
    "    unique_edge_pairs_with_weights = []\n",
    "    edges = []\n",
    "\n",
    "    games_for_team = games[games['TEAM_ABBREVIATION'] == team_abbreviation]\n",
    "    games_for_team = games_for_team.reset_index(drop=True)\n",
    "    only_home_teams = games_for_team['HOME_TEAM_ABBREVIATION'].tolist()\n",
    "    \n",
    "    for i in range(0,len(only_home_teams)-1):    \n",
    "        if only_home_teams[i] != team_abbreviation or only_home_teams[i+1] != team_abbreviation:\n",
    "            edges.append((only_home_teams[i], only_home_teams[i+1]))\n",
    "            \n",
    "            edge_pair = only_home_teams[i] + \"->\" + only_home_teams[i+1]\n",
    "            \n",
    "            if edge_pair not in unique_edge_pairs:\n",
    "                unique_edge_pairs.append(edge_pair)\n",
    "        \n",
    "                edge_pair_with_weights = []\n",
    "                edge_pair_with_weights.append(edge_pair)\n",
    "                edge_pair_with_weights.append('')\n",
    "                edge_pair_with_weights.append([{\"NUMBER_GAMES_PLAYED\": games_for_team.at[i, \"NUMBER_GAMES_PLAYED\"], \n",
    "                                                \"OFF_EFF\": games_for_team.at[i, \"OFF_EFF\"]*100,\n",
    "                                                \"DEF_EFF\": games_for_team.at[i, \"DEF_EFF\"]*100,\n",
    "                                                \"WL\": games_for_team.at[i, \"WL\"],\n",
    "                                                #\"E_OFF_RATING\": games_for_team.at[i, \"E_OFF_RATING\"],\n",
    "                                                #\"E_DEF_RATING\": games_for_team.at[i, \"E_DEF_RATING\"]\n",
    "                                               }])\n",
    "                edge_pair_with_weights.append(1)\n",
    "                unique_edge_pairs_with_weights.append(edge_pair_with_weights)\n",
    "                \n",
    "            else:\n",
    "                index = next((idx for idx, val in enumerate(unique_edge_pairs_with_weights) if edge_pair in val), None)\n",
    "        \n",
    "                unique_edge_pairs_with_weights[index][2].append({\"NUMBER_GAMES_PLAYED\": games_for_team.at[i, \"NUMBER_GAMES_PLAYED\"], \"OFF_EFF\": games_for_team.at[i, \"OFF_EFF\"]*100,\n",
    "                                                                \"DEF_EFF\": games_for_team.at[i, \"DEF_EFF\"]*100, \"WL\": games_for_team.at[i, \"WL\"],\n",
    "                                                                 #\"E_OFF_RATING\": games_for_team.at[i, \"E_OFF_RATING\"], \"E_DEF_RATING\": games_for_team.at[i, \"E_DEF_RATING\"]\n",
    "                                                                })\n",
    "        \n",
    "                unique_edge_pairs_with_weights[index][3] += 1\n",
    "            \n",
    "    unique_edge_pairs_list = []\n",
    "    for unique_edge_pair in unique_edge_pairs:\n",
    "        unique_edge_pairs_list.append(unique_edge_pair.split('->'))\n",
    "            \n",
    "    return unique_edge_pairs_list, unique_edge_pairs_with_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f625e79-e171-4e4c-9ef6-a220ee69018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_of_len_multiple_occur(unique_edge_pairs_with_weights, games_ahead):\n",
    "    unique_edge_pairs_list_dict = {}\n",
    "    consecutive_paths_of_games_ahead_len_dict = {}\n",
    "    consecutive_paths_of_games_ahead_len_list = []\n",
    "\n",
    "    for key in unique_edge_pairs_with_weights:\n",
    "\n",
    "        unique_edge_pairs_list = []\n",
    "\n",
    "        for edge_pair in unique_edge_pairs_with_weights[key]:\n",
    "            edge_pair_list = []\n",
    "            for edge_stats in edge_pair[2]:\n",
    "                edge_pair_list = [edge_pair[0], edge_stats['NUMBER_GAMES_PLAYED'], edge_stats['OFF_EFF'], edge_stats['DEF_EFF'], edge_stats[\"WL\"]]\n",
    "                unique_edge_pairs_list.append(edge_pair_list)\n",
    "                edge_pair_list = []\n",
    "        \n",
    "        unique_edge_pairs_list_sorted = sorted(unique_edge_pairs_list, key=lambda x:x[1])\n",
    "    \n",
    "        unique_edge_pairs_list_dict[key] = unique_edge_pairs_list_sorted\n",
    "        \n",
    "    for key in unique_edge_pairs_list_dict:\n",
    "    \n",
    "        consecutive_paths_of_games_ahead_len = []\n",
    "\n",
    "        len_edge_pairs_list = len(unique_edge_pairs_list_dict[key])\n",
    "        for i, edge_pair in enumerate(unique_edge_pairs_list_dict[key]):\n",
    "            # check if number games played is consecutive (i.e. 3->4->5) with no gaps\n",
    "            cur_games_played = edge_pair[1]\n",
    "\n",
    "            consecutive_games_played = True\n",
    "            for j in range(1, games_ahead+1):\n",
    "                if i+j < len_edge_pairs_list:\n",
    "                    if unique_edge_pairs_list_dict[key][i+j][1] != cur_games_played+j:\n",
    "                        consecutive_games_played=False\n",
    "                        break\n",
    "                else:\n",
    "                    consecutive_games_played=False\n",
    "                    break\n",
    "                    \n",
    "            if consecutive_games_played:\n",
    "                #game_paths_len_games_ahead = [] \n",
    "                total_off_eff = 0\n",
    "                total_def_eff = 0\n",
    "                w_l_record = \"\"\n",
    "                path_string = \"\"\n",
    "                for j in range(i, i+games_ahead+1):\n",
    "                    # get all values except num_games_player, then convert \n",
    "                    # team abbrev to one string value and average out off_eff and def_eff\n",
    "                    total_off_eff += unique_edge_pairs_list_dict[key][j][2]\n",
    "                    total_def_eff += unique_edge_pairs_list_dict[key][j][3]\n",
    "                    path_string_len = len(unique_edge_pairs_list_dict[key][j][0])\n",
    "                    path_string += unique_edge_pairs_list_dict[key][j][0][:path_string_len-3]\n",
    "                    w_l_record += unique_edge_pairs_list_dict[key][j][4]\n",
    "                    #game_paths_len_games_ahead.append(unique_edge_pairs_list_dict[key][j])\n",
    "\n",
    "                avg_off_eff = total_off_eff / (games_ahead+1)\n",
    "                avg_def_eff = total_def_eff / (games_ahead+1)\n",
    "                # adds all nodes in path to path_string\n",
    "                #path_string += unique_edge_pairs_list_dict[key][i+games_ahead][0][-3:]\n",
    "                # adds only starting nodes to path string, removes final arrow\n",
    "                path_string = path_string[:len(path_string)-2]\n",
    "\n",
    "\n",
    "                game_paths_len_games_ahead = [path_string, avg_off_eff, avg_def_eff, w_l_record]\n",
    "\n",
    "                consecutive_paths_of_games_ahead_len.append(game_paths_len_games_ahead)\n",
    "                consecutive_paths_of_games_ahead_len_list.append(game_paths_len_games_ahead)\n",
    "\n",
    "        consecutive_paths_of_games_ahead_len_dict[key] = consecutive_paths_of_games_ahead_len\n",
    "        \n",
    "    totals = {}\n",
    "    for edge_path in consecutive_paths_of_games_ahead_len_list:\n",
    "        if edge_path[0] in totals:\n",
    "            totals[edge_path[0]] += 1\n",
    "        else:\n",
    "            totals[edge_path[0]] = 1\n",
    "\n",
    "    num_distinct_paths = 0\n",
    "    for k, v in totals.items():    \n",
    "        if v > 1:\n",
    "            #print(f'{k}, {v}')\n",
    "            num_distinct_paths += 1\n",
    "\n",
    "    return totals, num_distinct_paths, consecutive_paths_of_games_ahead_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0391933d-a4ef-45c9-bcc0-0fd0b01f52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_travel_schedule_analysis(nba_team_details, games_df, games_ahead, edge_weight, travel_path_threshold):\n",
    "    edges = {}\n",
    "    unique_edge_pairs_with_weights = {}\n",
    "    #single_weighted_edges = {}\n",
    "\n",
    "    for key in nba_team_details:\n",
    "        edges[key], unique_edge_pairs_with_weights[key] = get_edges_for_team(key, games_df)\n",
    "        #single_weighted_edges[key] = convert_edge_weights(unique_edge_pairs_with_weights[key], edge_weight)\n",
    "        \n",
    "    #digraphs_for_games_df = {}\n",
    "    \n",
    "    #for key in nba_team_details:\n",
    "       # digraphs_for_games_df[key] = nx.DiGraph(single_weighted_edges[key])\n",
    "        #print(f'Team Abbrev: {key}, # Nodes: {len(networks_2016_17[key].nodes())}, # Edges: {len(networks_2016_17[key].edges())}\\n')\n",
    "        \n",
    "    paths_len_game_ahead, num_distinct_paths, consecutive_paths_of_games_ahead_len_dict = get_paths_of_len_multiple_occur(unique_edge_pairs_with_weights, games_ahead)\n",
    "    print(f'games_ahead: {games_ahead}, num_distinct_paths: {num_distinct_paths}')\n",
    "    \n",
    "    paths_of_game_ahead_over_threshold = []\n",
    "    exists_path_over_threshold = False\n",
    "    for k, v in paths_len_game_ahead.items():\n",
    "        if v > travel_path_threshold:\n",
    "            exists_path_over_threshold = True\n",
    "            paths_of_game_ahead_over_threshold.append(k)\n",
    "            #print(f'{k}, {v}')\n",
    "            \n",
    "    if exists_path_over_threshold: \n",
    "        i = 0\n",
    "        for key in nba_team_details:\n",
    "            for path in consecutive_paths_of_games_ahead_len_dict[key]:\n",
    "                if path[0] in paths_of_game_ahead_over_threshold:\n",
    "                    #print(path)\n",
    "                    i += 1\n",
    "        #print(f'Number of paths with {games_ahead+1} nodes: {i}')\n",
    "    else:\n",
    "        print(f'There are no paths with {games_ahead+1} nodes that exist more than {travel_path_threshold} times in the entire schedule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085521e9-099e-4c05-a158-80189c2bf47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 1610612760,\n",
       " 'NICKNAME': 'Thunder',\n",
       " 'CITY': 'Oklahoma City',\n",
       " 'FULL_NAME': 'Oklahoma City Thunder',\n",
       " 'LAT': '35.4729886',\n",
       " 'LON': '-97.5170536'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_team_details = get_team_details()\n",
    "nba_team_details['OKC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05273a8-86d3-4c7c-9553-c41edb44e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_2016_17 = load_nba_game_data()\n",
    "games_2017_18 = load_nba_game_data(base_filename='games_2017_18')\n",
    "games_2018_19 = load_nba_game_data(base_filename='games_2018_19')\n",
    "games_2015_16 = load_nba_game_data(base_filename='games_2015_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b586dc3-996f-4756-9c66-ca4f6784796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_ahead: 1, num_distinct_paths: 350\n",
      "games_ahead: 2, num_distinct_paths: 56\n",
      "games_ahead: 3, num_distinct_paths: 0\n",
      "There are no paths with 4 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 4, num_distinct_paths: 0\n",
      "There are no paths with 5 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 5, num_distinct_paths: 0\n",
      "There are no paths with 6 nodes that exist more than 2 times in the entire schedule\n"
     ]
    }
   ],
   "source": [
    "run_travel_schedule_analysis(nba_team_details, games_2015_16, 1, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2015_16, 2, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2015_16, 3, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2015_16, 4, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2015_16, 5, \"OFF_EFF\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a654e8b2-5830-4643-915f-8ab0000e8144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_ahead: 1, num_distinct_paths: 382\n",
      "games_ahead: 2, num_distinct_paths: 41\n",
      "There are no paths with 3 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 3, num_distinct_paths: 2\n",
      "There are no paths with 4 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 4, num_distinct_paths: 0\n",
      "There are no paths with 5 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 5, num_distinct_paths: 0\n",
      "There are no paths with 6 nodes that exist more than 2 times in the entire schedule\n"
     ]
    }
   ],
   "source": [
    "run_travel_schedule_analysis(nba_team_details, games_2016_17, 1, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2016_17, 2, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2016_17, 3, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2016_17, 4, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2016_17, 5, \"OFF_EFF\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66041a87-af64-46a9-b58d-7a2eb049b233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_ahead: 1, num_distinct_paths: 387\n",
      "games_ahead: 2, num_distinct_paths: 46\n",
      "games_ahead: 3, num_distinct_paths: 1\n",
      "There are no paths with 4 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 4, num_distinct_paths: 0\n",
      "There are no paths with 5 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 5, num_distinct_paths: 0\n",
      "There are no paths with 6 nodes that exist more than 2 times in the entire schedule\n"
     ]
    }
   ],
   "source": [
    "run_travel_schedule_analysis(nba_team_details, games_2017_18, 1, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2017_18, 2, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2017_18, 3, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2017_18, 4, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2017_18, 5, \"OFF_EFF\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a2bfa3d-ef0c-406b-a1d7-609bd4558d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_ahead: 1, num_distinct_paths: 370\n",
      "games_ahead: 2, num_distinct_paths: 36\n",
      "games_ahead: 3, num_distinct_paths: 2\n",
      "There are no paths with 4 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 4, num_distinct_paths: 0\n",
      "There are no paths with 5 nodes that exist more than 2 times in the entire schedule\n",
      "games_ahead: 5, num_distinct_paths: 0\n",
      "There are no paths with 6 nodes that exist more than 2 times in the entire schedule\n"
     ]
    }
   ],
   "source": [
    "run_travel_schedule_analysis(nba_team_details, games_2018_19, 1, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2018_19, 2, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2018_19, 3, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2018_19, 4, \"OFF_EFF\", 2)\n",
    "run_travel_schedule_analysis(nba_team_details, games_2018_19, 5, \"OFF_EFF\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa33fec-b26a-466c-9876-a3bfc1ee177a",
   "metadata": {},
   "source": [
    "### Laplacian Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06469f84-5873-4db1-9608-c2a34da49090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.directed_combinatorial_laplacian_matrix(network_2016_17_okc_digraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed437e51-ad5a-44d2-853f-65cbd48425bf",
   "metadata": {},
   "source": [
    "### All Pairs Dijkstra's Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ff0c0-3d5c-4033-bbcd-6282112db829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths_len_3_to_5 = []\n",
    "\n",
    "for n, (dist, path) in nx.all_pairs_dijkstra(network_2016_17_okc_digraph):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cec9db-3225-4ec7-9d4f-04acf4b83cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All pairs shortest path\n",
    "dict(nx.all_pairs_shortest_path(network_2016_17_okc_digraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5d13c-fc6f-459b-bd01-680aff104890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.dag_longest_path(network_2016_17_okc_digraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24a565-0c30-4f2b-9905-b68655a0a1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.johnson(network_2016_17_digraph, weight=\"weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
